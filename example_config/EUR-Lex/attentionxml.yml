data_name: EUR-Lex
training_file: data/EUR-Lex/train.txt
test_file: data/EUR-Lex/test.txt
# pretrained embeddings
embed_file: glove.840B.300d

# preprocessing
min_vocab_freq: 1
max_seq_length: 500

# AttentionXML-related parameters
cluster_size: 8
beam_width: 64

# dataloader
batch_size: 40
val_size: 200
shuffle: true

# eval
eval_batch_size: 40
monitor_metrics: [P@1, P@3, P@5, nDCG@3, nDCG@5, RP@3, RP@5]
val_metric: nDCG@5

# train
seed: 1337
epochs: 30
optimizer: adam
learning_rate: 0.001
# early stopping
patience: 30

# model
model_name: AttentionXML
network_config:
  embed_dropout: 0.2
  post_encoder_dropout: 0.5
  rnn_dim: 512
  rnn_layers: 1
  linear_size: [256]
  freeze_embed_training: True
